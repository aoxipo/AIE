{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d9099e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc5e2aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34 as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d660f614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pvtv2 import pvt_v2_b2\n",
    "from model.model import BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67203b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "Impression = 23\n",
    "HyperF_Type = 5\n",
    "HyperF_Area = 3\n",
    "HyperF_Fovea = 2\n",
    "HyperF_ExtraFovea = 18\n",
    "HyperF_Y = 4\n",
    "HypoF_Type = 3\n",
    "HypoF_Area = 3\n",
    "HypoF_Fovea = 2\n",
    "HypoF_ExtraFovea = 17\n",
    "HypoF_Y = 5\n",
    "CNV = 2\n",
    "Vascular_abnormality = 15\n",
    "Pattern = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9dae9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.Impression_classifier = nn.Sequential(nn.Linear(middle_channel[0], self.Impression))\n",
      "self.HyperF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[1], self.HyperF_Type))\n",
      "self.HyperF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[2], self.HyperF_Area))\n",
      "self.HyperF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[3], self.HyperF_Fovea))\n",
      "self.HyperF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[4], self.HyperF_ExtraFovea))\n",
      "self.HyperF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[5], self.HyperF_Y))\n",
      "self.HypoF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[6], self.HypoF_Type))\n",
      "self.HypoF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[7], self.HypoF_Area))\n",
      "self.HypoF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[8], self.HypoF_Fovea))\n",
      "self.HypoF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[9], self.HypoF_ExtraFovea))\n",
      "self.HypoF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[10], self.HypoF_Y))\n",
      "self.CNV_classifier = nn.Sequential(nn.Linear(middle_channel[11], self.CNV))\n",
      "self.Vascular_abnormality_classifier = nn.Sequential(nn.Linear(middle_channel[12], self.Vascular_abnormality))\n",
      "self.Pattern_classifier = nn.Sequential(nn.Linear(middle_channel[13], self.Pattern))\n",
      "return  Impression_res, HyperF_Type_res, HyperF_Area_res, HyperF_Fovea_res, HyperF_ExtraFovea_res, HyperF_Y_res, HypoF_Type_res, HypoF_Area_res, HypoF_Fovea_res, HypoF_ExtraFovea_res, HypoF_Y_res, CNV_res, Vascular_abnormality_res, Pattern_res,\n"
     ]
    }
   ],
   "source": [
    "data_key = [ \"Impression\", \"HyperF_Type\", \"HyperF_Area\", \"HyperF_Fovea\", \"HyperF_ExtraFovea\", \"HyperF_Y\", \n",
    "      \"HypoF_Type\" ,\"HypoF_Area\",\"HypoF_Fovea\", \"HypoF_ExtraFovea\"\n",
    "    ,\"HypoF_Y\",\"CNV\",\"Vascular_abnormality\",\"Pattern\"]\n",
    "ans = \"return \"\n",
    "for index in range(len(data_key)):\n",
    "    print(f\"self.{data_key[index]}_classifier = nn.Sequential(nn.Linear(middle_channel[{index}], self.{data_key[index]}))\")\n",
    "    # print(f\"{data_key[index]}_res = self.{data_key[index]}_classifier(x[{index}])\")\n",
    "    ans += f\" {data_key[index]}_res,\"\n",
    "print(ans ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b71997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \n",
    "    # 类别数量\n",
    "    Impression = 23 # 0\n",
    "    HyperF_Type = 5 # 1\n",
    "    HyperF_Area = 3 # 2\n",
    "    HyperF_Fovea = 2 # 3\n",
    "    HyperF_ExtraFovea = 18 # 4\n",
    "    HyperF_Y = 4 #           5  \n",
    "    HypoF_Type = 3 #         6 \n",
    "    HypoF_Area = 3 #         7\n",
    "    HypoF_Fovea = 2 #        8\n",
    "    HypoF_ExtraFovea = 17 #  9\n",
    "    HypoF_Y = 5           #  10\n",
    "    CNV = 2               #  11\n",
    "    Vascular_abnormality = 15 # 12\n",
    "    Pattern = 14              # 13\n",
    "    # [0,1,6,7,9,10,11,13]\n",
    "    # [2,3,4,5,8,12]\n",
    "    def __init__(self, middle_channel):\n",
    "        super().__init__()\n",
    "        self.Impression_classifier = nn.Sequential(nn.Linear(middle_channel[0], self.Impression))\n",
    "        self.HyperF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[1], self.HyperF_Type))\n",
    "        self.HyperF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[2], self.HyperF_Area))\n",
    "        self.HyperF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[3], self.HyperF_Fovea))\n",
    "        self.HyperF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[4], self.HyperF_ExtraFovea))\n",
    "        self.HyperF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[5], self.HyperF_Y))\n",
    "        self.HypoF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[6], self.HypoF_Type))\n",
    "        self.HypoF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[7], self.HypoF_Area))\n",
    "        self.HypoF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[8], self.HypoF_Fovea))\n",
    "        self.HypoF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[9], self.HypoF_ExtraFovea))\n",
    "        self.HypoF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[10], self.HypoF_Y))\n",
    "        self.CNV_classifier = nn.Sequential(nn.Linear(middle_channel[11], self.CNV))\n",
    "        self.Vascular_abnormality_classifier = nn.Sequential(nn.Linear(middle_channel[12], self.Vascular_abnormality))\n",
    "        self.Pattern_classifier = nn.Sequential(nn.Linear(middle_channel[13], self.Pattern))\n",
    "    def forward(self, x):\n",
    "#         x,x2 = x\n",
    "        Impression_res = self.Impression_classifier(x[0])\n",
    "        HyperF_Type_res = self.HyperF_Type_classifier(x[1])\n",
    "        HyperF_Area_res = self.HyperF_Area_classifier(x[2])\n",
    "        HyperF_Fovea_res = self.HyperF_Fovea_classifier(x[3])\n",
    "        HyperF_ExtraFovea_res = self.HyperF_ExtraFovea_classifier(x[4])\n",
    "        HyperF_Y_res = self.HyperF_Y_classifier(x[5])\n",
    "        HypoF_Type_res = self.HypoF_Type_classifier(x[6])\n",
    "        HypoF_Area_res = self.HypoF_Area_classifier(x[7])\n",
    "        HypoF_Fovea_res = self.HypoF_Fovea_classifier(x[8])\n",
    "        HypoF_ExtraFovea_res = self.HypoF_ExtraFovea_classifier(x[9])\n",
    "        HypoF_Y_res = self.HypoF_Y_classifier(x[10])\n",
    "        CNV_res = self.CNV_classifier(x[11])\n",
    "        Vascular_abnormality_res = self.Vascular_abnormality_classifier(x[12])\n",
    "        Pattern_res = self.Pattern_classifier(x[13])\n",
    "        return  [\n",
    "            Impression_res, HyperF_Type_res, HyperF_Area_res, HyperF_Fovea_res, HyperF_ExtraFovea_res, \n",
    "            HyperF_Y_res, HypoF_Type_res, HypoF_Area_res, HypoF_Fovea_res, \n",
    "            HypoF_ExtraFovea_res, HypoF_Y_res, CNV_res, Vascular_abnormality_res, \n",
    "            Pattern_res \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae7203ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class CBLK(nn.Module):\n",
    "    def __init__(self, inc, ouc):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inc, ouc, 3, 1, 1),\n",
    "            nn.BatchNorm2d(ouc),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "# sppf  atn\n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self, inc, ouc):\n",
    "        super().__init__()\n",
    "        \n",
    "        d = ouc//4\n",
    "        print(\"inc {}\".format(inc))\n",
    "        self.c1 = nn.Sequential(\n",
    "            CBLK(inc[1], d),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            CBLK(inc[6], d)\n",
    "        )\n",
    "        self.c3 = nn.Sequential(\n",
    "            CBLK(576, d)\n",
    "        )\n",
    "        self.c4 = nn.Sequential(\n",
    "            CBLK(1024, d)\n",
    "        )\n",
    "        self.proj_k = nn.Conv2d(4*d, 4*d,kernel_size=2)\n",
    "        self.out = nn.Conv2d(4*d, ouc,kernel_size=2)\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4):\n",
    "        c1 = self.c1(x1)\n",
    "        c2 = self.c2(x2)\n",
    "        c3 = self.c3(x3)\n",
    "        c4 = self.c4(x4)\n",
    "        \n",
    "        c21 = torch.cat([c1,c2], 1)\n",
    "        print(\"c3 {} self.down(c21) {} \".format(c3.size(),self.down(c21).size()))\n",
    "        \n",
    "        print(\"c1 {} c2 {} c3 {} c4 {} \".format(c1.size(),c2.size(),c3.size(),c4.size() ))\n",
    "#      c3 torch.Size([2, 36, 14, 14]) self.down(c21) torch.Size([2, 72, 14, 14]) \n",
    "# c1 torch.Size([2, 36, 28, 28]) c2 torch.Size([2, 36, 28, 28]) c3 torch.Size([2, 36, 14, 14]) c4 torch.Size([2, 36, 7, 7])    \n",
    "\n",
    "        c321 = torch.cat([self.down(c21), c3],dim=1)\n",
    "        \n",
    "        v = torch.cat([self.down(c321), c4],dim=1)\n",
    "        \n",
    "        k = self.proj_k(v)\n",
    "        pool = torch.nn.AvgPool2d(kernel_size=2, stride=1, padding=0)\n",
    "        resized_v = pool(v)\n",
    "\n",
    "        q = self.softmax(torch.sum(self.down(self.down(self.down(c1 + c2) + c3) + c4), dim=1, keepdim=True))\n",
    "        print(\"vsize  {}\".format(v.size()))\n",
    "        print(\"self.drop(k) {}\".format(self.drop(k).size()))\n",
    "        \n",
    "        x = resized_v @ self.drop(k)\n",
    "        print(\"x  {}\".format(x.size()))\n",
    "        \n",
    "        print(\"q  {}\".format(q.size()))\n",
    "        \n",
    "        \n",
    "        q_resized = F.interpolate(q, size=(6, 6), mode='bilinear', align_corners=True)\n",
    "         # 现在 q_resized 的大小是 [2, 1, 6, 6]，你可以尝试 x @ q_resized\n",
    "\n",
    "        feature = x @ q_resized\n",
    "        return self.out(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3954a1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neck(nn.Module): \n",
    "    def __init__(self, pvt_decode, resnet_decode, num_conv_layers = [ 8, 6]):\n",
    "        super(Neck, self).__init__()\n",
    "        self.pvt_decode = pvt_decode\n",
    "        self.resnet_decode = resnet_decode\n",
    "        middle_channel = 144\n",
    "        print(\"inc {}\".format(pvt_decode+ resnet_decode))\n",
    "        self.focus = Fusion( pvt_decode + resnet_decode, middle_channel)\n",
    "      \n",
    "        d = [ CBLK(middle_channel, middle_channel) for i in range(num_conv_layers[0]) ]\n",
    "        d.append(CBLK(middle_channel, 32 ))\n",
    "        self.conv_layers1 = nn.Sequential(*d)\n",
    "        \n",
    "        d = [ CBLK(middle_channel, middle_channel) for i in range(num_conv_layers[1]) ]\n",
    "        d.append(CBLK(middle_channel, 32 ))\n",
    "        self.conv_layers2 = nn.Sequential(*d)\n",
    "        self.conv = nn.ModuleList()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear=nn.ModuleList()\n",
    "        \n",
    "        for i in range(14):\n",
    "            self.linear.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(800, 1024),#middle_channel*7*7, 1024),\n",
    "                    nn.Linear(1024, 768),\n",
    "                    nn.Linear(768, 512)\n",
    "                )\n",
    "            )\n",
    "           \n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        fuse1 = torch.cat([x[0] , y[0]], 1)\n",
    "        fuse2 = torch.cat([x[1] , y[1]], 1)\n",
    "        fuse3 = torch.cat([x[2] , y[2]], 1)\n",
    "        fuse4 = torch.cat([x[3] , y[3]], 1)\n",
    "        print(\"fuse1 {} fuse2 {} fuse3 {} fuse4 {} \".format(fuse1.size(),fuse2.size(),fuse3.size(),fuse4.size()))\n",
    "        combine_feature = self.focus( fuse1,fuse2,fuse3,fuse4 )\n",
    "        \n",
    "        out1 = self.conv_layers1(combine_feature)\n",
    "        out2 = self.conv_layers2(combine_feature)\n",
    "        \n",
    "        high = self.flatten(out1)\n",
    "        low = self.flatten(out2)\n",
    "        ans = []\n",
    "        for idx in range(14):\n",
    "            if idx < 8:\n",
    "                ans.append(self.linear[idx](high))\n",
    "            else:\n",
    "                ans.append(self.linear[idx](low))\n",
    "            \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f19ea7f",
   "metadata": {
    "code_folding": [
     23,
     33
    ]
   },
   "outputs": [],
   "source": [
    "class DUAL(BaseLine):\n",
    "    # 类别数量\n",
    "    Impression = 23 # 0\n",
    "    HyperF_Type = 5 # 1\n",
    "    HyperF_Area = 3 # 2\n",
    "    HyperF_Fovea = 2 # 3\n",
    "    HyperF_ExtraFovea = 18 # 4\n",
    "    HyperF_Y = 4 #           5  \n",
    "    HypoF_Type = 3 #         6 \n",
    "    HypoF_Area = 3 #         7\n",
    "    HypoF_Fovea = 2 #        8\n",
    "    HypoF_ExtraFovea = 17 #  9\n",
    "    HypoF_Y = 5           #  10\n",
    "    CNV = 2               #  11\n",
    "    Vascular_abnormality = 15 # 12\n",
    "    Pattern = 14              # 13\n",
    "    \n",
    "    # [0,1,6,7,9,10,11,13]\n",
    "    \n",
    "    # [2,3,4,5,8,12]\n",
    "    def __init__(self, neck_num = [8,6]) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # PVT 提取特征\n",
    "        path = './pretrained_pth/pvt_v2_b2.pth' # 找我要\n",
    "        self.backbone = pvt_v2_b2()  # [64, 128, 320, 512]\n",
    "        #  save_model = torch.load(path)\n",
    "        #         model_dict = self.backbone.state_dict()\n",
    "        #         state_dict = {k: v for k, v in save_model.items() if k in model_dict.keys()}\n",
    "        #         model_dict.update(state_dict)\n",
    "        #         self.backbone.load_state_dict(model_dict)\n",
    "        #         n_p = sum(x.numel() for x in self.backbone.parameters()) # number parameters\n",
    "        #         n_g = sum(x.numel() for x in self.backbone.parameters() if x.requires_grad)  # number gradients\n",
    "        #         print(f\"pvt Summary: {len(list(self.backbone.modules()))} layers, {n_p} parameters, {n_p/1e6} M, {n_g} gradients\")\n",
    "        # RESNET 特征提取\n",
    "        self.resnet = resnet(pretrained=True) \n",
    "        # self.resnet.load_state_dict(torch.load('pretrained_pth/resnet34-43635321.pth')) # 找我要\n",
    "        n_p = sum(x.numel() for x in self.resnet.parameters()) # number parameters\n",
    "        n_g = sum(x.numel() for x in self.resnet.parameters() if x.requires_grad)  # number gradients\n",
    "        print(f\"ResNet Summary: {len(list(self.resnet.modules()))} layers, {n_p} parameters, {n_p/1e6} M, {n_g} gradients\")\n",
    "#         self.neck = Neck( pvt_feature = [64, 128, 320, 512], resnet_feature = [64, 128, 256, 512], num_conv_layers = neck_num)\n",
    "        self.neck = Neck( [64, 128, 320, 512],  [64, 128, 256, 512], num_conv_layers = neck_num)\n",
    "        self.head = Head(middle_channel=[512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512])\n",
    "\n",
    "    def pvt_backbone(self, x):\n",
    "        pvt_x = x.clone().detach()\n",
    "        if x.shape[1] == 1:\n",
    "            pvt_x = torch.cat([pvt_x,pvt_x,pvt_x], 1)\n",
    "\n",
    "        pvt = self.backbone(pvt_x)\n",
    "        # pvt_decode: x1:torch.Size([2, 64, 56, 56]), c2:torch.Size([2, 128, 28, 28]), c3:torch.Size([2, 320, 14, 14]), c4:torch.Size([2, 512, 7, 7])\n",
    "        \n",
    "        return pvt\n",
    "\n",
    "    def resnet_backbone(self, x):\n",
    "        x   = self.resnet.conv1(x)\n",
    "        x   = self.resnet.bn1(x)\n",
    "        x   = self.resnet.relu(x)\n",
    "        \n",
    "        # - low-level features\n",
    "        x0  = self.resnet.maxpool(x)       \n",
    "        x1  = self.resnet.layer1(x0)       \n",
    "        x2  = self.resnet.layer2(x1)       \n",
    "        x3  = self.resnet.layer3(x2)     \n",
    "        x4  = self.resnet.layer4(x3)     \n",
    "        #res: x1:torch.Size([2, 64, 56, 56]), c2:torch.Size([2, 128, 28, 28]), c3:torch.Size([2, 256, 14, 14]), c4:torch.Size([2, 512, 7, 7])\n",
    "        #print(f\"res:x:{x.shape}, x1:{x1.shape}, c2:{x2.shape}, c3:{x3.shape}, c4:{x4.shape}\")\n",
    "        # print(f\"pvt_decode:x:{x.shape}, x1:{pvt_decode[0].shape}, c2:{pvt_decode[1].shape}, c3:{pvt_decode[2].shape}, c4:{pvt_decode[3].shape}\")\n",
    "        return x1,x2, x3,x4\n",
    "    def forward(self, x):\n",
    "        pvt_decode = self.pvt_backbone(x)     \n",
    "        res_decode = self.resnet_backbone(x)\n",
    "        feature_neck = self.neck( pvt_decode, res_decode)\n",
    "        classifier = self.head(feature_neck)\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b59a6dd4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\soft\\Anaconda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet Summary: 116 layers, 21797672 parameters, 21.797672 M, 21797672 gradients\n",
      "inc [64, 128, 320, 512, 64, 128, 256, 512]\n",
      "inc [64, 128, 320, 512, 64, 128, 256, 512]\n"
     ]
    }
   ],
   "source": [
    "model = DUAL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9722ba67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Impression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74371d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image = torch.zeros((2,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49e20e49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuse1 torch.Size([2, 128, 56, 56]) fuse2 torch.Size([2, 256, 28, 28]) fuse3 torch.Size([2, 576, 14, 14]) fuse4 torch.Size([2, 1024, 7, 7]) \n",
      "c3 torch.Size([2, 36, 14, 14]) self.down(c21) torch.Size([2, 72, 14, 14]) \n",
      "c1 torch.Size([2, 36, 28, 28]) c2 torch.Size([2, 36, 28, 28]) c3 torch.Size([2, 36, 14, 14]) c4 torch.Size([2, 36, 7, 7]) \n",
      "vsize  torch.Size([2, 144, 7, 7])\n",
      "self.drop(k) torch.Size([2, 144, 6, 6])\n",
      "x  torch.Size([2, 144, 6, 6])\n",
      "q  torch.Size([2, 1, 3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_22776\\705888060.py:66: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  q = self.softmax(torch.sum(self.down(self.down(self.down(c1 + c2) + c3) + c4), dim=1, keepdim=True))\n"
     ]
    }
   ],
   "source": [
    "ans = model(batch_image)\n",
    "# print(ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "264e4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in tensor 0: 0.16741356253623962\n",
      "Max value in tensor 1: 0.11652518808841705\n",
      "Max value in tensor 2: 0.04199444130063057\n",
      "Max value in tensor 3: 0.029410652816295624\n",
      "Max value in tensor 4: 0.18974129855632782\n",
      "Max value in tensor 5: 0.11601413041353226\n",
      "Max value in tensor 6: 0.13982243835926056\n",
      "Max value in tensor 7: 0.24016134440898895\n",
      "Max value in tensor 8: -0.07836799323558807\n",
      "Max value in tensor 9: 0.1898948848247528\n",
      "Max value in tensor 10: 0.03460843116044998\n",
      "Max value in tensor 11: -0.08105338364839554\n",
      "Max value in tensor 12: 0.19331173598766327\n",
      "Max value in tensor 13: 0.13111911714076996\n"
     ]
    }
   ],
   "source": [
    "for i, tensor in enumerate(ans):\n",
    "    max_value = torch.max(tensor)\n",
    "    print(f\"Max value in tensor {i}: {max_value.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "168d497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f6b8679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.897959183673468"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45982e25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
