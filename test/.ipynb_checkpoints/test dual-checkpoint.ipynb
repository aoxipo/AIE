{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d927434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T08:26:52.280664Z",
     "start_time": "2023-12-01T08:26:52.266701Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd6b6c2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T08:26:53.055163Z",
     "start_time": "2023-12-01T08:26:53.045191Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34 as resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9bdf3d37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T08:26:53.523474Z",
     "start_time": "2023-12-01T08:26:53.504525Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.pvtv2 import pvt_v2_b2\n",
    "from model.model import BaseLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6924d6a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T08:26:54.173781Z",
     "start_time": "2023-12-01T08:26:54.155407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.Impression_classifier = nn.Sequential(nn.Linear(middle_channel[0], self.Impression))\n",
      "self.HyperF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[1], self.HyperF_Type))\n",
      "self.HyperF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[2], self.HyperF_Area))\n",
      "self.HyperF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[3], self.HyperF_Fovea))\n",
      "self.HyperF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[4], self.HyperF_ExtraFovea))\n",
      "self.HyperF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[5], self.HyperF_Y))\n",
      "self.HypoF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[6], self.HypoF_Type))\n",
      "self.HypoF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[7], self.HypoF_Area))\n",
      "self.HypoF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[8], self.HypoF_Fovea))\n",
      "self.HypoF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[9], self.HypoF_ExtraFovea))\n",
      "self.HypoF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[10], self.HypoF_Y))\n",
      "self.CNV_classifier = nn.Sequential(nn.Linear(middle_channel[11], self.CNV))\n",
      "self.Vascular_abnormality_classifier = nn.Sequential(nn.Linear(middle_channel[12], self.Vascular_abnormality))\n",
      "self.Pattern_classifier = nn.Sequential(nn.Linear(middle_channel[13], self.Pattern))\n",
      "return  Impression_res, HyperF_Type_res, HyperF_Area_res, HyperF_Fovea_res, HyperF_ExtraFovea_res, HyperF_Y_res, HypoF_Type_res, HypoF_Area_res, HypoF_Fovea_res, HypoF_ExtraFovea_res, HypoF_Y_res, CNV_res, Vascular_abnormality_res, Pattern_res,\n"
     ]
    }
   ],
   "source": [
    "data_key = [ \"Impression\", \"HyperF_Type\", \"HyperF_Area\", \"HyperF_Fovea\", \"HyperF_ExtraFovea\", \"HyperF_Y\", \n",
    "      \"HypoF_Type\" ,\"HypoF_Area\",\"HypoF_Fovea\", \"HypoF_ExtraFovea\"\n",
    "    ,\"HypoF_Y\",\"CNV\",\"Vascular_abnormality\",\"Pattern\"]\n",
    "ans = \"return \"\n",
    "for index in range(len(data_key)):\n",
    "    print(f\"self.{data_key[index]}_classifier = nn.Sequential(nn.Linear(middle_channel[{index}], self.{data_key[index]}))\")\n",
    "    # print(f\"{data_key[index]}_res = self.{data_key[index]}_classifier(x[{index}])\")\n",
    "    ans += f\" {data_key[index]}_res,\"\n",
    "print(ans ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76de559f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T08:26:57.316983Z",
     "start_time": "2023-12-01T08:26:57.287484Z"
    }
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \n",
    "    # 类别数量\n",
    "    Impression = 23 # 0\n",
    "    HyperF_Type = 5 # 1\n",
    "    HyperF_Area = 3 # 2\n",
    "    HyperF_Fovea = 2 # 3\n",
    "    HyperF_ExtraFovea = 18 # 4\n",
    "    HyperF_Y = 4 #           5  \n",
    "    HypoF_Type = 3 #         6 \n",
    "    HypoF_Area = 3 #         7\n",
    "    HypoF_Fovea = 2 #        8\n",
    "    HypoF_ExtraFovea = 17 #  9\n",
    "    HypoF_Y = 5           #  10\n",
    "    CNV = 2               #  11\n",
    "    Vascular_abnormality = 15 # 12\n",
    "    Pattern = 14              # 13\n",
    "    # [0,1,6,7,9,10,11,13]\n",
    "    # [2,3,4,5,8,12]\n",
    "    def __init__(self, middle_channel):\n",
    "        super().__init__()\n",
    "        self.Impression_classifier = nn.Sequential(nn.Linear(middle_channel[0], self.Impression))\n",
    "        self.HyperF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[1], self.HyperF_Type))\n",
    "        self.HyperF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[2], self.HyperF_Area))\n",
    "        self.HyperF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[3], self.HyperF_Fovea))\n",
    "        self.HyperF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[4], self.HyperF_ExtraFovea))\n",
    "        self.HyperF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[5], self.HyperF_Y))\n",
    "        self.HypoF_Type_classifier = nn.Sequential(nn.Linear(middle_channel[6], self.HypoF_Type))\n",
    "        self.HypoF_Area_classifier = nn.Sequential(nn.Linear(middle_channel[7], self.HypoF_Area))\n",
    "        self.HypoF_Fovea_classifier = nn.Sequential(nn.Linear(middle_channel[8], self.HypoF_Fovea))\n",
    "        self.HypoF_ExtraFovea_classifier = nn.Sequential(nn.Linear(middle_channel[9], self.HypoF_ExtraFovea))\n",
    "        self.HypoF_Y_classifier = nn.Sequential(nn.Linear(middle_channel[10], self.HypoF_Y))\n",
    "        self.CNV_classifier = nn.Sequential(nn.Linear(middle_channel[11], self.CNV))\n",
    "        self.Vascular_abnormality_classifier = nn.Sequential(nn.Linear(middle_channel[12], self.Vascular_abnormality))\n",
    "        self.Pattern_classifier = nn.Sequential(nn.Linear(middle_channel[13], self.Pattern))\n",
    "    def forward(self, x):\n",
    "#         x,x2 = x\n",
    "        Impression_res = self.Impression_classifier(x[0])\n",
    "        HyperF_Type_res = self.HyperF_Type_classifier(x[1])\n",
    "        HyperF_Area_res = self.HyperF_Area_classifier(x[2])\n",
    "        HyperF_Fovea_res = self.HyperF_Fovea_classifier(x[3])\n",
    "        HyperF_ExtraFovea_res = self.HyperF_ExtraFovea_classifier(x[4])\n",
    "        HyperF_Y_res = self.HyperF_Y_classifier(x[5])\n",
    "        HypoF_Type_res = self.HypoF_Type_classifier(x[6])\n",
    "        HypoF_Area_res = self.HypoF_Area_classifier(x[7])\n",
    "        HypoF_Fovea_res = self.HypoF_Fovea_classifier(x[8])\n",
    "        HypoF_ExtraFovea_res = self.HypoF_ExtraFovea_classifier(x[9])\n",
    "        HypoF_Y_res = self.HypoF_Y_classifier(x[10])\n",
    "        CNV_res = self.CNV_classifier(x[11])\n",
    "        Vascular_abnormality_res = self.Vascular_abnormality_classifier(x[12])\n",
    "        Pattern_res = self.Pattern_classifier(x[13])\n",
    "        return  [\n",
    "            Impression_res, HyperF_Type_res, HyperF_Area_res, HyperF_Fovea_res, HyperF_ExtraFovea_res, \n",
    "            HyperF_Y_res, HypoF_Type_res, HypoF_Area_res, HypoF_Fovea_res, \n",
    "            HypoF_ExtraFovea_res, HypoF_Y_res, CNV_res, Vascular_abnormality_res, \n",
    "            Pattern_res \n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df2a80b",
   "metadata": {},
   "source": [
    "# 特征对齐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0019c9a",
   "metadata": {},
   "source": [
    "a * b + c * d -> (a + c ) * (b + d) -> a * b + c * d + c * b + a * d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bbc6e060",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:10:41.462974Z",
     "start_time": "2023-12-01T09:10:41.450901Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AFC(nn.Module):            \n",
    "    def __init__(self, features_list, out_features, r = 2, L=32):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            features: input channel dimensionality.\n",
    "            r: the radio for compute d, the length of z.                 2      \n",
    "            L: the minimum dim of the vector z in paper, default 32\n",
    "        \"\"\"\n",
    "        super(AFC, self).__init__()\n",
    "        features = out_features\n",
    "        d = max(int(features/r), L)\n",
    "        self.M = 1# len(features_list)\n",
    "        self.features = features\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(features, d)\n",
    "        self.fcs = nn.ModuleList()\n",
    "        for i in range(self.M):\n",
    "            self.fcs.append(\n",
    "                nn.Linear(d, features)\n",
    "            )\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        \n",
    "    def normal(self, x):\n",
    "        return (x - x.min() + 1e-8)/(x.max() - x.min() + 1e-8)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        total = len(x) \n",
    "        for i in range(total):\n",
    "            fea = x[i].unsqueeze_(dim = 0).unsqueeze_(dim = 1)\n",
    "            # print(fea.shape)\n",
    "            if i == 0:\n",
    "                feas = fea\n",
    "            else:\n",
    "                feas = torch.cat([feas, fea], dim=1)\n",
    "        # print(feas.shape)\n",
    "        fea_U = torch.sum(feas, dim=1)#.unsqueeze(0)\n",
    "        fea_U = self.normal(fea_U)\n",
    "        # print(\"feau:\", fea_U.shape)\n",
    "        fea_s = self.gap(fea_U).squeeze(dim=-1).squeeze(dim=-1)\n",
    "        # print(fea_s.shape, self.fc)   \n",
    "        fea_z = self.fc(fea_s)\n",
    "        # print( fea_z.shape )\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            vector = fc(fea_z).unsqueeze_(dim=1)\n",
    "            if i == 0:\n",
    "                attention_vectors = vector\n",
    "            else:\n",
    "                attention_vectors = torch.cat([attention_vectors, vector], dim=1)\n",
    "           \n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        attention_vectors = attention_vectors.unsqueeze(-1).unsqueeze(-1)\n",
    "        # print(attention_vectors.shape)\n",
    "        fea_v = fea_U * attention_vectors.squeeze(1)\n",
    "        return fea_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "260a9ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:10:41.740964Z",
     "start_time": "2023-12-01T09:10:41.729491Z"
    }
   },
   "outputs": [],
   "source": [
    "a = AFC([32, 32,32,32], 32)\n",
    "sk = AFC([32, 32,32,32], 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bd50793f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:10:42.066641Z",
     "start_time": "2023-12-01T09:10:42.025751Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = torch.zeros((2, 32, 64, 64))\n",
    "feature2 = torch.zeros((128, 32, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4782c56b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:10:42.852960Z",
     "start_time": "2023-12-01T09:10:42.327366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feau: torch.Size([1, 32, 64, 64])\n",
      "torch.Size([1, 1, 32, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 64])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(feature2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "94bab77a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T09:06:12.003490Z",
     "start_time": "2023-12-01T09:06:11.986535Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(a, \"./pkl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e24fe70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T07:53:58.064363Z",
     "start_time": "2023-11-30T07:53:58.018486Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64, 64])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b475e71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T08:15:21.488449Z",
     "start_time": "2023-11-30T08:15:21.422786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a627be0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T07:41:24.315118Z",
     "start_time": "2023-11-30T07:41:24.304639Z"
    }
   },
   "outputs": [],
   "source": [
    "feature = [torch.zeros(1,64,24,24 ) for i in range(16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d734a3eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T07:41:24.764588Z",
     "start_time": "2023-11-30T07:41:24.648899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 16, 64, 24, 24])\n",
      "feau: torch.Size([1, 1, 64, 24, 24])\n",
      "torch.Size([1, 1, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x64 and 32x32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 41\u001b[0m, in \u001b[0;36mAFC.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m fea_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgap(fea_U)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(fea_s\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 41\u001b[0m fea_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfea_s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m( fea_z\u001b[38;5;241m.\u001b[39mshape )\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, fc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfcs):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x64 and 32x32)"
     ]
    }
   ],
   "source": [
    "a(feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d66070b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:43:53.855346Z",
     "start_time": "2023-11-29T01:43:53.840387Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [[torch.zeros(32,3,32,32),torch.zeros(32,15,16,16),torch.zeros(32,24,12,12) ] for i in range(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce59e1ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:50:26.557056Z",
     "start_time": "2023-11-29T01:50:26.551082Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [[],[],[],[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1546f507",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:50:27.433107Z",
     "start_time": "2023-11-29T01:50:27.416398Z"
    }
   },
   "outputs": [],
   "source": [
    "a[0].append(1)\n",
    "a[1].append(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3831788",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-29T01:50:29.657559Z",
     "start_time": "2023-11-29T01:50:29.648584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [32], [], []]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df29dff",
   "metadata": {},
   "source": [
    "backbone # ML 随机森林 森林 boast svm # neck head DL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1826ed",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76be0df8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:41:09.492002Z",
     "start_time": "2023-12-01T01:41:09.472056Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class CBLK(nn.Module):\n",
    "    def __init__(self, inc, ouc, k = 3, s = 1, p = 1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(inc, ouc, k, s, p),\n",
    "            nn.BatchNorm2d(ouc),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "# sppf  atn\n",
    "class Fusion(nn.Module):\n",
    "    def __init__(self, inc, ouc):\n",
    "        super().__init__()\n",
    "        \n",
    "        d = ouc//4\n",
    "        print(\"inc {}\".format(inc))\n",
    "        self.c1 = nn.Sequential(\n",
    "            CBLK(inc[0], d),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.c2 = nn.Sequential(\n",
    "            CBLK(inc[1], d)\n",
    "        )\n",
    "        self.c3 = nn.Sequential(\n",
    "            CBLK(inc[2], d)\n",
    "        )\n",
    "        self.c4 = nn.Sequential(\n",
    "            CBLK(inc[3], d)\n",
    "        )\n",
    "        self.proj_k = nn.Conv2d(4*d, 4*d, 1,1 )\n",
    "        self.out = nn.Conv2d(4*d, ouc, 1,1 )\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.down = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x1, x2, x3, x4):\n",
    "        c1 = self.c1(x1)\n",
    "        c2 = self.c2(x2)\n",
    "        c3 = self.c3(x3)\n",
    "        c4 = self.c4(x4)\n",
    "        \n",
    "        c21 = torch.cat([c1,c2], 1)\n",
    "        print(\"c3 {} self.down(c21) {} \".format(c3.size(),self.down(c21).size()))\n",
    "        \n",
    "        print(\"c1 {} c2 {} c3 {} c4 {} \".format(c1.size(),c2.size(),c3.size(),c4.size() ))\n",
    "#      c3 torch.Size([2, 36, 14, 14]) self.down(c21) torch.Size([2, 72, 14, 14]) \n",
    "# c1 torch.Size([2, 36, 28, 28]) c2 torch.Size([2, 36, 28, 28]) c3 torch.Size([2, 36, 14, 14]) c4 torch.Size([2, 36, 7, 7])    \n",
    "\n",
    "        c321 = torch.cat([self.down(c21), c3],dim=1)\n",
    "        \n",
    "        v = torch.cat([self.down(c321), c4],dim=1)\n",
    "        k = self.proj_k(v)\n",
    "        q = self.softmax(torch.sum((self.down(self.down(c1 + c2) + c3) + c4), dim=1, keepdim=True))\n",
    "        \n",
    "        x = v @ self.drop(k)\n",
    "        feature = x @ q\n",
    "        out = self.out(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4659e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:41:11.376332Z",
     "start_time": "2023-12-01T01:41:11.363367Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Neck(nn.Module): \n",
    "    def __init__(self, pvt_decode, resnet_decode, num_conv_layers = [ 8, 6]):\n",
    "        super(Neck, self).__init__()\n",
    "        self.pvt_decode = pvt_decode\n",
    "        self.resnet_decode = resnet_decode\n",
    "        middle_channel = 144\n",
    "        last_channel = 32\n",
    "        middle_afc = 40\n",
    "        print(\"inc {}\".format(np.array(pvt_decode) + np.array(resnet_decode)))\n",
    "        self.focus = Fusion( np.array(pvt_decode) + np.array(resnet_decode), middle_channel)\n",
    "      \n",
    "        d = [ CBLK(middle_channel, middle_channel,1,1,0) for i in range(num_conv_layers[0]) ]\n",
    "        d.append(CBLK(middle_channel, last_channel ,1,1,0))\n",
    "        self.conv_layers1 = nn.Sequential(*d)\n",
    "        \n",
    "        d = [ CBLK(middle_channel, middle_channel,1,1,0) for i in range(num_conv_layers[1]) ]\n",
    "        d.append(CBLK(middle_channel, last_channel ,1,1,0))\n",
    "        self.conv_layers2 = nn.Sequential(*d)\n",
    "        self.conv = nn.ModuleList()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear=nn.ModuleList()\n",
    "        \n",
    "        for i in range(14):\n",
    "            self.linear.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(last_channel*7*7, 1024),#middle_channel*7*7, 1024),\n",
    "                    nn.Linear(1024, 768),\n",
    "                    nn.Linear(768, 512)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        fuse1 = torch.cat([x[0] , y[0]], 1)\n",
    "        fuse2 = torch.cat([x[1] , y[1]], 1)\n",
    "        fuse3 = torch.cat([x[2] , y[2]], 1)\n",
    "        fuse4 = torch.cat([x[3] , y[3]], 1)\n",
    "        # print(\"fuse1 {} fuse2 {} fuse3 {} fuse4 {} \".format(fuse1.size(),fuse2.size(),fuse3.size(),fuse4.size()))\n",
    "        combine_feature = self.focus( fuse1,fuse2,fuse3,fuse4 )\n",
    "        # print(\"combine feature:\", combine_feature.shape)\n",
    "        out1 = self.conv_layers1(combine_feature)\n",
    "        out2 = self.conv_layers2(combine_feature)\n",
    "        high = self.flatten(out1)\n",
    "        low = self.flatten(out2)\n",
    "        # print(high.shape, low.shape)\n",
    "        ans = []\n",
    "        for idx in range(14):\n",
    "            if idx < 8:\n",
    "                ans.append(self.linear[idx](high))\n",
    "            else:\n",
    "                ans.append(self.linear[idx](low))\n",
    "            \n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e294331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:45:35.443905Z",
     "start_time": "2023-12-01T01:45:35.422503Z"
    },
    "code_folding": [
     23,
     33
    ]
   },
   "outputs": [],
   "source": [
    "class DUAL(BaseLine): #pipline\n",
    "    # 类别数量\n",
    "    Impression = 23 # 0\n",
    "    HyperF_Type = 5 # 1\n",
    "    HyperF_Area = 3 # 2\n",
    "    HyperF_Fovea = 2 # 3\n",
    "    HyperF_ExtraFovea = 18 # 4\n",
    "    HyperF_Y = 4 #           5  \n",
    "    HypoF_Type = 3 #         6 \n",
    "    HypoF_Area = 3 #         7\n",
    "    HypoF_Fovea = 2 #        8\n",
    "    HypoF_ExtraFovea = 17 #  9\n",
    "    HypoF_Y = 5           #  10\n",
    "    CNV = 2               #  11\n",
    "    Vascular_abnormality = 15 # 12\n",
    "    Pattern = 14              # 13\n",
    "    \n",
    "    # [0,1,6,7,9,10,11,13]\n",
    "    \n",
    "    # [2,3,4,5,8,12]\n",
    "    def __init__(self, neck_num = [8,6]) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # PVT 提取特征\n",
    "        path = './model/pretrained_pth/pvt_v2_b2.pth' # 找我要\n",
    "        self.backbone = pvt_v2_b2()  # [64, 128, 320, 512]\n",
    "#         save_model = torch.load(path)\n",
    "#         print(\"load parameter:\", path)\n",
    "#         model_dict = self.backbone.state_dict()\n",
    "#         state_dict = {k: v for k, v in save_model.items() if k in model_dict.keys()}\n",
    "#         model_dict.update(state_dict)\n",
    "#         self.backbone.load_state_dict(model_dict)\n",
    "        n_p = sum(x.numel() for x in self.backbone.parameters()) # number parameters\n",
    "        n_g = sum(x.numel() for x in self.backbone.parameters() if x.requires_grad)  # number gradients\n",
    "        print(f\"pvt Summary: {len(list(self.backbone.modules()))} layers, {n_p} parameters, {n_p/1e6} M, {n_g} gradients\")\n",
    "        # RESNET 特征提取\n",
    "        self.resnet = resnet(pretrained=True) \n",
    "        # self.resnet.load_state_dict(torch.load('pretrained_pth/resnet34-43635321.pth')) # 找我要\n",
    "        n_p = sum(x.numel() for x in self.resnet.parameters()) # number parameters\n",
    "        n_g = sum(x.numel() for x in self.resnet.parameters() if x.requires_grad)  # number gradients\n",
    "        print(f\"ResNet Summary: {len(list(self.resnet.modules()))} layers, {n_p} parameters, {n_p/1e6} M, {n_g} gradients\")\n",
    "#         self.neck = Neck( pvt_feature = [64, 128, 320, 512], resnet_feature = [64, 128, 256, 512], num_conv_layers = neck_num)\n",
    "        pvt_feature = [64, 128, 320, 512]\n",
    "        resnet_feature = [64, 128, 256, 512]\n",
    "        self.neck = Neck( pvt_feature, resnet_feature, num_conv_layers = neck_num)\n",
    "        self.head = Head(middle_channel=[ 512 for i in range(14) ])\n",
    "        self.afc = nn.ModuleList()\n",
    "        self.afc1 = nn.ModuleList()\n",
    "        for i in range(4):\n",
    "            self.afc.append( \n",
    "                AFC([ pvt_feature[i] for ii in range(4)], pvt_feature[i])\n",
    "            )\n",
    "            self.afc1.append( \n",
    "                AFC([ resnet_feature[i] for ii in range(4)], resnet_feature[i])\n",
    "            )\n",
    "        \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def pvt_backbone(self, x):\n",
    "        pvt_x = x # .clone().detach()\n",
    "        pvt_x = torch.stack(pvt_x, 0)\n",
    "        # print(pvt_x.shape)\n",
    "        # if x.shape[1] == 1:\n",
    "        #     pvt_x = torch.cat([pvt_x,pvt_x,pvt_x], 1)\n",
    "\n",
    "        pvt = self.backbone(pvt_x)\n",
    "        # pvt_decode: x1:torch.Size([2, 64, 56, 56]), c2:torch.Size([2, 128, 28, 28]), c3:torch.Size([2, 320, 14, 14]), c4:torch.Size([2, 512, 7, 7])\n",
    "        return pvt\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def resnet_backbone(self, x):\n",
    "        # if x.shape[1] == 1:\n",
    "        #     x = torch.cat([x,x,x], 1)\n",
    "        x = torch.stack(x, 0)\n",
    "        x   = self.resnet.conv1(x)\n",
    "        x   = self.resnet.bn1(x)\n",
    "        x   = self.resnet.relu(x)\n",
    "        \n",
    "        # - low-level features\n",
    "        x0  = self.resnet.maxpool(x)       \n",
    "        x1  = self.resnet.layer1(x0)       \n",
    "        x2  = self.resnet.layer2(x1)       \n",
    "        x3  = self.resnet.layer3(x2)     \n",
    "        x4  = self.resnet.layer4(x3)     \n",
    "        #res: x1:torch.Size([2, 64, 56, 56]), c2:torch.Size([2, 128, 28, 28]), c3:torch.Size([2, 256, 14, 14]), c4:torch.Size([2, 512, 7, 7])\n",
    "        #print(f\"res:x:{x.shape}, x1:{x1.shape}, c2:{x2.shape}, c3:{x3.shape}, c4:{x4.shape}\")\n",
    "        # print(f\"pvt_decode:x:{x.shape}, x1:{pvt_decode[0].shape}, c2:{pvt_decode[1].shape}, c3:{pvt_decode[2].shape}, c4:{pvt_decode[3].shape}\")\n",
    "        return x1,x2, x3,x4\n",
    "    \n",
    "\n",
    "    def ext_feature(self, x_list):\n",
    "        pvt_decode_list = [[],[],[],[]]\n",
    "        res_decode_list = [[],[],[],[]]\n",
    "        # print(\"encode:\", len(x_list))\n",
    "        for x in x_list:\n",
    "            # x = x.unsqueeze(0)\n",
    "            pvt_decode = self.pvt_backbone(x)     \n",
    "            res_decode = self.resnet_backbone(x)\n",
    "            for i in range(4):\n",
    "                # print( pvt_decode[i].shape, res_decode[i].shape )\n",
    "                pvt_decode_list[i].append( pvt_decode[i] )\n",
    "                res_decode_list[i].append( res_decode[i] )\n",
    "                \n",
    "        pvt_decode = [[],[],[],[]]\n",
    "        res_decode = [[],[],[],[]]\n",
    "\n",
    "        for i in range(len(x_list)):\n",
    "            # print(len(pvt_decode_list[0]))\n",
    "            # print(pvt_decode_list[0][i].shape)\n",
    "            for j in range(4):\n",
    "                pvt_feature = self.afc[j](pvt_decode_list[j][i])\n",
    "                # print(f\"pvt:{i} {pvt_decode_list[j][i].min()} {pvt_decode_list[j][i].max()}\")\n",
    "                res_feature = self.afc1[j](res_decode_list[j][i])\n",
    "                # print(f\"res:{i} {res_decode_list[j][i].min()} {res_decode_list[j][i].max()}\")\n",
    "                pvt_decode[j].append(pvt_feature)\n",
    "                res_decode[j].append(res_feature)\n",
    "\n",
    "        for i in range(4):\n",
    "            pvt_decode[i] = torch.cat(pvt_decode[i] , 0)\n",
    "            res_decode[i] = torch.cat(res_decode[i] , 0)\n",
    "        return pvt_decode, res_decode\n",
    "\n",
    "    def forward(self, x_list):\n",
    "        pvt_decode, res_decode = self.ext_feature(x_list)\n",
    "        print(\"a::\", pvt_decode.shape, res_decode.shape)\n",
    "        feature_neck = self.neck( pvt_decode, res_decode)\n",
    "        classifier = self.head(feature_neck)\n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66025103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:45:37.685946Z",
     "start_time": "2023-12-01T01:45:36.374182Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvt Summary: 319 layers, 24849856 parameters, 24.849856 M, 24849856 gradients\n",
      "ResNet Summary: 116 layers, 21797672 parameters, 21.797672 M, 21797672 gradients\n",
      "inc [ 128  256  576 1024]\n",
      "inc [ 128  256  576 1024]\n"
     ]
    }
   ],
   "source": [
    "model = DUAL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40b5649a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:45:37.700907Z",
     "start_time": "2023-12-01T01:45:37.687943Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = [ [torch.zeros(3,224,224) for i in range(12)], [torch.zeros(3,224,224) for j in range(8)] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57bb8b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:45:40.789044Z",
     "start_time": "2023-12-01T01:45:39.098565Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = model.ext_feature(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57e96e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:53:19.044994Z",
     "start_time": "2023-12-01T01:53:19.011087Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(a[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75bd7f72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:52:07.743498Z",
     "start_time": "2023-12-01T01:52:07.659344Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\_tensor.py:1061\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1056\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[0;32m   1057\u001b[0m ):\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (element \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1063\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Tensor.__contains__ only supports Tensor or scalar, but you passed in a <class 'str'>."
     ]
    }
   ],
   "source": [
    "'nan' in a[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71d506cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T01:46:35.339250Z",
     "start_time": "2023-12-01T01:46:35.329208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 128, 28, 28]),\n",
       " torch.Size([2, 320, 14, 14]),\n",
       " torch.Size([2, 512, 7, 7]),\n",
       " torch.Size([2, 64, 56, 56]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][1].shape, a[0][2].shape, a[0][3].shape, a[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4b58ab50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 7, 7])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neck.conv_layers1( torch.zeros(2,144,7,7) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17bf35c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuse1 torch.Size([2, 128, 56, 56]) fuse2 torch.Size([2, 256, 28, 28]) fuse3 torch.Size([2, 576, 14, 14]) fuse4 torch.Size([2, 1024, 7, 7]) \n",
      "c3 torch.Size([2, 36, 14, 14]) self.down(c21) torch.Size([2, 72, 14, 14]) \n",
      "c1 torch.Size([2, 36, 28, 28]) c2 torch.Size([2, 36, 28, 28]) c3 torch.Size([2, 36, 14, 14]) c4 torch.Size([2, 36, 7, 7]) \n",
      "torch.Size([2, 144, 7, 7])\n",
      "combine feature: torch.Size([2, 144, 7, 7])\n",
      "torch.Size([2, 1568]) torch.Size([2, 1568])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DentaLink\\.conda\\envs\\tooth\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_image = torch.zeros((2,3,224,224))\n",
    "ans = model(batch_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09232e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f55596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Impression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "70fc0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in tensor 0: 0.1530095934867859\n",
      "Max value in tensor 1: 0.18238547444343567\n",
      "Max value in tensor 2: 0.12089018523693085\n",
      "Max value in tensor 3: 0.06578119844198227\n",
      "Max value in tensor 4: 0.19104671478271484\n",
      "Max value in tensor 5: 0.07583684474229813\n",
      "Max value in tensor 6: 0.13103041052818298\n",
      "Max value in tensor 7: 0.1117761880159378\n",
      "Max value in tensor 8: 0.13914397358894348\n",
      "Max value in tensor 9: 0.15929335355758667\n",
      "Max value in tensor 10: 0.20197774469852448\n",
      "Max value in tensor 11: 0.10965007543563843\n",
      "Max value in tensor 12: 0.17611879110336304\n",
      "Max value in tensor 13: 0.14662733674049377\n"
     ]
    }
   ],
   "source": [
    "for i, tensor in enumerate(ans):\n",
    "    max_value = torch.max(tensor)\n",
    "    print(f\"Max value in tensor {i}: {max_value.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1848f251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*7*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dc04500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.897959183673468"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1024/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de6e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tooth",
   "language": "python",
   "name": "tooth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
